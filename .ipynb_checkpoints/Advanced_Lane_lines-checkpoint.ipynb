{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "\n",
    "# prepare object points\n",
    "nx = 9#TODO: enter the number of inside corners in x\n",
    "ny = 6#TODO: enter the number of inside corners in y\n",
    "\n",
    "# Make a list of calibration images\n",
    "objpoints=[]\n",
    "imgpoints=[]\n",
    "images=glob.glob('C://Users//Shivam.Chawla01//CarND-Advanced-Lane-Lines//camera_cal//calibration*.jpg')\n",
    "for fname in images:\n",
    "    img=mpimg.imread(fname)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    \n",
    "\n",
    "    objp=np.zeros((9*6,3),np.float32)\n",
    "    objp[:,:2]=np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "    if(ret==True):\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "    \n",
    "        img=cv2.drawChessboardCorners(img,(9,6),corners,ret)\n",
    "        plt.imshow(img)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    if(orient=='x'):\n",
    "        sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0)\n",
    "        abs_sobel=np.absolute(sobelx)\n",
    "    elif(orient=='y'):\n",
    "        sobely=cv2.Sobel(gray,cv2.CV_64F,0,1)\n",
    "        abs_sobel=np.absolute(sobely)\n",
    "    scaled_sobel=np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    sxbinary=np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel>=thresh[0]) & (scaled_sobel<=thresh[1])]=1\n",
    "    grad_binary=sxbinary\n",
    "    return grad_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x=cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobel_y=cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    abs_Sobel_x=np.absolute(sobel_x)\n",
    "    abs_Sobel_y=np.absolute(sobel_y)\n",
    "    grad_drtn=np.arctan2(abs_Sobel_y,abs_Sobel_x)\n",
    "    binary_output=np.zeros_like(grad_drtn)\n",
    "    binary_output[(grad_drtn>=thresh[0]) & (grad_drtn<=thresh[1])]=1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobel_x=cv2.Sobel(gray,cv2.CV_64F,1,0)\n",
    "    sobel_y=cv2.Sobel(gray,cv2.CV_64F,0,1)\n",
    "    # 3) Calculate the magnitude\n",
    "    mag_sobel=np.sqrt(sobel_x**2+sobel_y**2)\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel=np.uint8(255*mag_sobel/np.max(mag_sobel))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    sxbinary=np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel>=mag_thresh[0]) & (scaled_sobel<=mag_thresh[1])]=1\n",
    "    mag_binary=sxbinary\n",
    "    return mag_binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    S=hls[:,:,2]\n",
    "    binary_output=np.zeros_like(S)\n",
    "    # 3) Return a binary image of threshold result\n",
    "    binary_output[(S>thresh[0]) & (S<=thresh[1])]=1\n",
    "    #binary_output = np.copy(img) # placeholder line\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "        # Use cv2.calibrateCamera() and cv2.undistort()\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "        udst=cv2.undistort(img,mtx,dist,None,mtx)\n",
    "        #undist = np.copy(img)  # Delete this line\n",
    "        return udst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "    img_size=(img.shape[1],img.shape[0])\n",
    "    hls_threshold=hls_select(undistorted, (170, 255))\n",
    "    gradx = abs_sobel_thresh(undistorted, orient='x', thresh=(50, 100))\n",
    "    mag_threshold=mag_thresh(undistorted,3,(90, 255))\n",
    "    dir_thresh=dir_threshold(undistorted,3,(0.7, 1.3))\n",
    "    combined_binary = np.zeros_like(gradx)\n",
    "    combined_binary[(hls_threshold == 1) | (gradx == 1) | (mag_threshold==1) | (dir_threshold==1)] = 1\n",
    "    ksize=3\n",
    "    src=np.float32([[526,503],[801,503],[884,549],[461,549]])\n",
    "            # c) define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "    dst=np.float32([[200,300],[900,300],[900,500],[200,500]])\n",
    "            # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    M=cv2.getPerspectiveTransform(src,dst)\n",
    "    warped=cv2.warpPerspective(combined_binary ,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "    warped=np.dstack((warped,warped,warped))*255\n",
    "    return warped\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected non-empty vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-166b325e39d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[0mleft_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlefty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleftx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrighty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m \u001b[0mright_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrighty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[0mploty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\numpy\\lib\\polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected non-empty vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D or 2D array for y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected non-empty vector for x"
     ]
    }
   ],
   "source": [
    "image = 'C://Users//Shivam.Chawla01//CarND-Advanced-Lane-Lines//test_images//test4.jpg'\n",
    "\n",
    "img=mpimg.imread(image)\n",
    "img_size=(img.shape[1],img.shape[0])\n",
    "\n",
    "# TODO: Write a function that takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "\n",
    "#undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "\n",
    "combined=pipeline(img)\n",
    "\n",
    "\n",
    "# Assuming you have created a warped binary image called \"binary_warped\"\n",
    "# Take a histogram of the bottom half of the image\n",
    "histogram = np.sum(combined[combined.shape[0]//2:,:], axis=0)\n",
    "# Create an output image to draw on and  visualize the result\n",
    "#out_img = np.dstack((combined, combined, combined))*255\n",
    "out_img=combined\n",
    "# Find the peak of the left and right halves of the histogram\n",
    "# These will be the starting point for the left and right lines\n",
    "midpoint = np.int(histogram.shape[0]//2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set height of windows\n",
    "window_height = np.int(combined.shape[0]//nwindows)\n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "nonzero = combined.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "# Current positions to be updated for each window\n",
    "leftx_current = leftx_base\n",
    "rightx_current = rightx_base\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 50\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "left_lane_inds = []\n",
    "right_lane_inds = []\n",
    "\n",
    "# Step through the windows one by one\n",
    "for window in range(nwindows):\n",
    "    # Identify window boundaries in x and y (and right and left)\n",
    "    win_y_low = combined.shape[0] - (window+1)*window_height\n",
    "    win_y_high = combined.shape[0] - window*window_height\n",
    "    win_xleft_low = leftx_current - margin\n",
    "    win_xleft_high = leftx_current + margin\n",
    "    win_xright_low = rightx_current - margin\n",
    "    win_xright_high = rightx_current + margin\n",
    "    # Draw the windows on the visualization image\n",
    "    cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "    (0,255,0), 2) \n",
    "    cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "    (0,255,0), 2) \n",
    "    # Identify the nonzero pixels in x and y within the window\n",
    "    good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "    (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "    good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "    (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "    # Append these indices to the lists\n",
    "    left_lane_inds.append(good_left_inds)\n",
    "    right_lane_inds.append(good_right_inds)\n",
    "    # If you found > minpix pixels, recenter next window on their mean position\n",
    "    if len(good_left_inds) > minpix:\n",
    "        leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "    if len(good_right_inds) > minpix:        \n",
    "        rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "# Concatenate the arrays of indices\n",
    "left_lane_inds = np.concatenate(left_lane_inds)\n",
    "right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "# Extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "print(righty)\n",
    "right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "ploty = np.linspace(0, combined.shape[0]-1, combined.shape[0] )\n",
    "\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n",
    "\n",
    "\n",
    "\n",
    "# plt.imshow(warped)\n",
    "histogram = np.sum(combined[combined.shape[0]//2:,:], axis=0)\n",
    "plt.plot(histogram)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(combined, cmap='gray')\n",
    "ax2.set_title('Thresholded Grad. Dir.', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,20)\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
